## 移动研究院

### 1、BERT和GPT的区别？它们主要用于什么任务？
Bert和GPT都是深度学习中的NLP模型，它们都使用了Transformer的结构。区别主要在于Bert是encoder部分，是一种自编码模型。而GPT是一种自回归模型。

Bert在训练的时候会随机屏蔽（mask）一些词，然后根据上下文的信息来预测被屏蔽的词。这样模型可以学习到整个文本的语义信息，适合于下游的任务，如：问答，文本分类、实体识别等。

GPT的自回归模型，在训练的时候会利用前面的词来预测下一个词，这样模型学习到文本的生成规律，适合于文本生成、宅哟啊、对话等任务。

### 2、梯度消失的原因？有什么方法可以缓解？

### 3、正则化的作用？L1正则化和L2正则化的区别？

### 4、transformer轻量化的方式？如何减轻其计算复杂度？

### 5、GBDT、XGBoost、随机森林的区别？

### 6、SVM多分类的方式？

### 7、怎么判断一个函数是凸函数？

